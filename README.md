# Real-TimeLogProcessingPipeline


This project implements a real-time data pipeline for processing and analyzing logs using Apache Kafka, Apache Spark, Docker. The pipeline is designed to handle high-throughput log data, enabling efficient ingestion, transformation, and querying of large datasets.

Key Features
Data Ingestion: Logs are collected and streamed using Apache Kafka.
Stream Processing: Apache Spark processes the data in real time, performing transformations and aggregations.
Storage: Cassandra (future)
Analytics: unknown.
Technologies: Apache Kafka, Apache Spark, Docker, WSL

![image](https://github.com/user-attachments/assets/1eb63e71-f6fb-4767-aea8-26b0decae2d8)

Kafka_producer algorithm in action:
![image](https://github.com/user-attachments/assets/15e273e1-aa3e-4484-bec4-c4a9aa87c442)

Checking stream data directly in Kafka:
![image](https://github.com/user-attachments/assets/d3aee9c3-f4c7-4913-938f-7f6895e489ce)

Console output at spark machine:
![image](https://github.com/user-attachments/assets/bc51e39c-ff00-48d6-af81-70dcb9460bc4)

CASSANDRA:
![image](https://github.com/user-attachments/assets/0cf7b9a9-7cbb-438e-bc93-a9ecb1cef55d)


